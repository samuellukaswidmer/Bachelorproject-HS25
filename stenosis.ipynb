{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfac973",
   "metadata": {},
   "source": [
    "# Data Analysis Of Medical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f342a95",
   "metadata": {},
   "source": [
    "## 1. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "951b9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling and Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "###\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "###\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "260cd187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2310, 649)\n",
      "   OUTCOME_3Kat_KHK           Alter_0  geschlecht waist_0             WHR_0  \\\n",
      "0                 2  56,9691991786448           0     112  ,982456140350877   \n",
      "1                 2  69,4976043805613           0     104              1,04   \n",
      "2                 2  72,0492813141684           0     129  ,941605839416058   \n",
      "3                 2  70,8145106091718           0      99  ,876106194690266   \n",
      "4                 2  62,1601642710472           1     125               NaN   \n",
      "\n",
      "              BMI_0  currsmo0  RR_syst_0  RR_diast_0  Pulse_Pressure  ...  \\\n",
      "0  32,8731097961867         0      130.0        80.0            50.0  ...   \n",
      "1  30,1102788964583         0      160.0        70.0            90.0  ...   \n",
      "2  44,7348800491207         0      140.0        90.0            50.0  ...   \n",
      "3  26,2595847484332         0      130.0        90.0            40.0  ...   \n",
      "4  42,4366343891054         1      180.0       100.0            80.0  ...   \n",
      "\n",
      "   SMC231l  SMC232l  SMC233l  SMC240l  SMC241l SMC242l  SMC243l  SMC244l  \\\n",
      "0     9,44     4,38     3,99     14,1     25,8     7,8     3,99     3,99   \n",
      "1     19,8     8,97     7,75     21,9     41,3    20,1     7,35      NaN   \n",
      "2     13,9     4,75     3,99     20,3     52,4    18,6     3,99     3,99   \n",
      "3       20     8,73     7,85     25,3     50,7      17        0      NaN   \n",
      "4     16,9     9,14      8,3     29,5       43    17,9     8,13        0   \n",
      "\n",
      "  SMC263l SMC264l  \n",
      "0    3,99    3,99  \n",
      "1    7,45    8,11  \n",
      "2    3,99    3,99  \n",
      "3    7,63    9,02  \n",
      "4     8,4    8,51  \n",
      "\n",
      "[5 rows x 649 columns]\n",
      "Value Counts (in %):\n",
      "OUTCOME_3Kat_KHK\n",
      "2    56.93\n",
      "1    27.36\n",
      "0    15.71\n",
      "Name: proportion, dtype: float64\n",
      "Number of nan\n",
      "OUTCOME_3Kat_KHK       0\n",
      "Alter_0                0\n",
      "geschlecht             0\n",
      "waist_0              191\n",
      "WHR_0                783\n",
      "                    ... \n",
      "SMC242l             1908\n",
      "SMC243l             1908\n",
      "SMC244l             1989\n",
      "SMC263l             1908\n",
      "SMC264l             1908\n",
      "Length: 649, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m3/k3b3svlj7tvdqbtttg5w9xfw0000gn/T/ipykernel_31154/2070728576.py:3: DtypeWarning: Columns (3,32,119,121,125,129,231,330,342,588) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=\";\", na_values=[\"\", \" \", \"NA\", \"N/A\", \"nan\", \"NaN\"])\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f316b9fd-55d9-4be3-9662-c54bb51dc756",
       "rows": [
        [
         "LTB4",
         "2303"
        ],
        [
         "PGE2",
         "2282"
        ],
        [
         "PGD2",
         "2282"
        ],
        [
         "PGaaC362l",
         "2275"
        ],
        [
         "@9SHODE",
         "2255"
        ],
        [
         "PGaaC361l",
         "2255"
        ],
        [
         "PGaaC341l",
         "2251"
        ],
        [
         "@15SHETE",
         "2221"
        ],
        [
         "@12SHETE",
         "2203"
        ],
        [
         "OAA_energy_m",
         "2154"
        ],
        [
         "OHKynurenine",
         "2151"
        ],
        [
         "lysoPCaC204",
         "2150"
        ],
        [
         "lysoPCaC203",
         "2150"
        ],
        [
         "lysoPCaC182",
         "2150"
        ],
        [
         "lysoPCaC240",
         "2150"
        ],
        [
         "lysoPCaC181",
         "2150"
        ],
        [
         "lysoPCaC260",
         "2150"
        ],
        [
         "PCaaC426",
         "2150"
        ],
        [
         "lysoPCaC170",
         "2150"
        ],
        [
         "lysoPCaC261",
         "2150"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 20
       }
      },
      "text/plain": [
       "LTB4            2303\n",
       "PGE2            2282\n",
       "PGD2            2282\n",
       "PGaaC362l       2275\n",
       "@9SHODE         2255\n",
       "PGaaC361l       2255\n",
       "PGaaC341l       2251\n",
       "@15SHETE        2221\n",
       "@12SHETE        2203\n",
       "OAA_energy_m    2154\n",
       "OHKynurenine    2151\n",
       "lysoPCaC204     2150\n",
       "lysoPCaC203     2150\n",
       "lysoPCaC182     2150\n",
       "lysoPCaC240     2150\n",
       "lysoPCaC181     2150\n",
       "lysoPCaC260     2150\n",
       "PCaaC426        2150\n",
       "lysoPCaC170     2150\n",
       "lysoPCaC261     2150\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file and look at contents\n",
    "file_path = \"T49.2_Sep2025_1_StGallen.csv\"\n",
    "df = pd.read_csv(file_path, sep=\";\", na_values=[\"\", \" \", \"NA\", \"N/A\", \"nan\", \"NaN\"])\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Proportions of classes\n",
    "print(\"Value Counts (in %):\")\n",
    "class_shares = df[\"OUTCOME_3Kat_KHK\"].value_counts(normalize=True) * 100\n",
    "print(class_shares.round(2))\n",
    "print(\"Number of nan\")\n",
    "print(df.isnull().sum())\n",
    "df.isnull().sum().sort_values(ascending=False).head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1427a0a1",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8ae0f",
   "metadata": {},
   "source": [
    "## 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ded209",
   "metadata": {},
   "source": [
    "1. FIRST TRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73841d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5584415584415584\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  9  19  45]\n",
      " [  4  29  93]\n",
      " [  9  34 220]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.12      0.19        73\n",
      "           1       0.35      0.23      0.28       126\n",
      "           2       0.61      0.84      0.71       263\n",
      "\n",
      "    accuracy                           0.56       462\n",
      "   macro avg       0.46      0.40      0.39       462\n",
      "weighted avg       0.51      0.56      0.51       462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Features (X) and target (y)\n",
    "X = df.drop(\"OUTCOME_3Kat_KHK\", axis=1)\n",
    "y = df[\"OUTCOME_3Kat_KHK\"]\n",
    "\n",
    "# 3. Encode categorical features if any\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 5. Train multinomial logistic regression model\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\"\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 7. Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9ec1c",
   "metadata": {},
   "source": [
    "### Accuracy  \n",
    "Sounds alright, but we know that **class 2 makes up 57% of the data**.  \n",
    "Our model isn’t better than a simple **“always class 2” predictor**.  \n",
    "\n",
    "---\n",
    "\n",
    "### Confusion Matrix  \n",
    "\n",
    "Class 0 – *No Stenosis* (15.7% of Data)  \n",
    "- Of the 73 real cases, only **9** are recognized correctly.  \n",
    "- **45** are incorrectly categorized as class 2.  \n",
    "\n",
    "Class 1 – *Light Stenosis* (27% of Data)  \n",
    "- **29 of 126** correct → recall **23%**.  \n",
    "- Most real class-1 cases are also categorized as class 2.  \n",
    "\n",
    "Class 2 – *Stenosis* (57% of Data)  \n",
    "- **220 of 263** correct → recall **84%**.  \n",
    "- Most misclassifications are confused with class 1.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad866f3f",
   "metadata": {},
   "source": [
    "2. SECOND TRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa81fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5324675324675324\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 10  22  41]\n",
      " [  8  36  82]\n",
      " [ 16  47 200]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.14      0.19        73\n",
      "           1       0.34      0.29      0.31       126\n",
      "           2       0.62      0.76      0.68       263\n",
      "\n",
      "    accuracy                           0.53       462\n",
      "   macro avg       0.42      0.39      0.39       462\n",
      "weighted avg       0.49      0.53      0.50       462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Load data\n",
    "file_path = \"T49.2_Sep2025_1_StGallen.csv\"\n",
    "df = pd.read_csv(file_path, sep=\";\")\n",
    "\n",
    "\n",
    "# 2. Features (X) and target (y)\n",
    "X = df.drop(\"OUTCOME_3Kat_KHK\", axis=1)\n",
    "y = df[\"OUTCOME_3Kat_KHK\"]\n",
    "\n",
    "# 3. Encode categorical features if any\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 5. Train multinomial logistic regression model with BALANCED CLASS WEIGHTS\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    class_weight=\"balanced\"   # NEW MEASURE: This should balance the classes\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 7. Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dce33c6",
   "metadata": {},
   "source": [
    "3. THIRD TRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fb617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m3/k3b3svlj7tvdqbtttg5w9xfw0000gn/T/ipykernel_31154/2807974015.py:16: DtypeWarning: Columns (3,32,119,121,125,129,231,330,342,588) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 393, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 418, 419, 421, 422, 423, 424, 425, 426, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 518, 519, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 587, 588, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4069264069264069\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 37  20  16]\n",
      " [ 44  39  43]\n",
      " [ 84  67 112]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.51      0.31        73\n",
      "           1       0.31      0.31      0.31       126\n",
      "           2       0.65      0.43      0.52       263\n",
      "\n",
      "    accuracy                           0.41       462\n",
      "   macro avg       0.40      0.41      0.38       462\n",
      "weighted avg       0.49      0.41      0.43       462\n",
      "\n",
      "\n",
      "Top 15 features by missingness (%):\n",
      "LTB4            99.70\n",
      "PGE2            98.79\n",
      "PGD2            98.79\n",
      "PGaaC362l       98.48\n",
      "@9SHODE         97.62\n",
      "PGaaC361l       97.62\n",
      "PGaaC341l       97.45\n",
      "@15SHETE        96.15\n",
      "@12SHETE        95.37\n",
      "OAA_energy_m    93.25\n",
      "OHKynurenine    93.12\n",
      "PCaaC384        93.07\n",
      "PCaaC364        93.07\n",
      "PCaaC322        93.07\n",
      "PCaaC323        93.07\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with proper NaN handling + imputation + OHE in a Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1) Load data and treat empty strings etc. as NaN\n",
    "file_path = \"T49.2_Sep2025_1_StGallen.csv\"\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    sep=\";\",\n",
    "    na_values=[\"\", \" \", \"NA\", \"N/A\", \"NaN\", \"nan\", None]\n",
    ")\n",
    "\n",
    "# 2) Split features/target (no manual get_dummies here; pipeline handles encoding)\n",
    "target_col = \"OUTCOME_3Kat_KHK\"\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# 3) Train-test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4) Preprocessing:\n",
    "#    - Numeric: median imputation\n",
    "#    - Categorical: most-frequent imputation -> cast to string -> OneHotEncoder\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"to_str\", FunctionTransformer(lambda X: X.astype(str))),  # unify types\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False))\n",
    "])\n",
    "\n",
    "# Select columns by dtype\n",
    "numeric_features = selector(dtype_include=np.number)(X_train)\n",
    "categorical_features = selector(dtype_exclude=np.number)(X_train)\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# 5) Model: multinomial logistic regression with class weighting\n",
    "logreg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "# 6) Full pipeline\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"logreg\", logreg)\n",
    "])\n",
    "\n",
    "# 7) Fit\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 8) Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional: quick missingness report (after correct NaN parsing)\n",
    "missing_pct = (X.isna().mean()*100).sort_values(ascending=False)\n",
    "print(\"\\nTop 15 features by missingness (%):\")\n",
    "print(missing_pct.head(15).round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d99aa1f",
   "metadata": {},
   "source": [
    "## 2.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Train XGBoost classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200,        # number of trees\n",
    "    learning_rate=0.1,       # shrinkage step\n",
    "    max_depth=5,             # tree depth\n",
    "    subsample=0.8,           # sample rows\n",
    "    colsample_bytree=0.8,    # sample features\n",
    "    random_state=42,\n",
    "    scale_pos_weight=None,   # can be used for imbalance, but start with None\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# 3. Evaluation\n",
    "print(\"Accuracy (XGBoost):\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3872fe",
   "metadata": {},
   "source": [
    "## 2.3 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e153fc",
   "metadata": {},
   "source": [
    "The Support Vector Machine is notoriously slow on data with high dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM comparison: LinearSVC vs. SVC (RBF) with PCA\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Train time: {train_time:.2f} s\")\n",
    "    print(f\"Accuracy:   {acc:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return acc\n",
    "\n",
    "# 1) Linear SVM (fast, good for many features)\n",
    "linear_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),   # works with sparse One-Hot; safe for dense too\n",
    "    (\"svm\", LinearSVC(\n",
    "        C=1.0,\n",
    "        class_weight=\"balanced\",   # handle imbalance\n",
    "        max_iter=10000,\n",
    "        dual=\"auto\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2) RBF SVM with PCA (reduce 649 dims -> ~100; speeds up and helps generalization)\n",
    "n_pca = min(100, X_train.shape[1], max(10, X_train.shape[0] - 1))  # cap at 100 comps\n",
    "svm_pca_rbf = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"pca\", PCA(n_components=n_pca, random_state=42)),\n",
    "    (\"svm\", SVC(\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        class_weight=\"balanced\",   # handle imbalance\n",
    "        probability=False,         # keep False for speed\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "acc_lin = evaluate_model(\"LinearSVC (scaled)\", linear_svm, X_train, y_train, X_test, y_test)\n",
    "acc_rbf = evaluate_model(f\"SVC RBF + PCA({n_pca})\", svm_pca_rbf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"- LinearSVC Accuracy:     {acc_lin:.4f}\")\n",
    "print(f\"- SVC RBF + PCA Accuracy: {acc_rbf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ec9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    macro_f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*78)\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(f\"Train time: {train_time:.2f} s\")\n",
    "    print(f\"Accuracy:   {acc:.4f} | Macro-F1: {macro_f1:.4f} | Balanced Acc: {bal_acc:.4f}\")\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    # digits=3 prevents Jupyter from collapsing; printing the string avoids truncation artifacts\n",
    "    report_str = classification_report(y_test, y_pred, digits=3, zero_division=0)\n",
    "    print(report_str)\n",
    "    print(\"=\"*78)\n",
    "    return {\"model\": name, \"accuracy\": acc, \"macro_f1\": macro_f1, \"balanced_acc\": bal_acc, \"train_time_s\": train_time}\n",
    "\n",
    "# 1) Linear SVM (fast, good for many features)\n",
    "linear_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),   # safe for one-hot / sparse-like design\n",
    "    (\"svm\", LinearSVC(\n",
    "        C=1.0,\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=10000,\n",
    "        dual=\"auto\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2) RBF SVM with PCA (reduce 649 -> ~100 comps to speed up & improve generalization)\n",
    "n_pca = min(100, X_train.shape[1], max(10, X_train.shape[0] - 1))  # cap at 100 comps\n",
    "svm_pca_rbf = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"pca\", PCA(n_components=n_pca, random_state=42)),\n",
    "    (\"svm\", SVC(\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        class_weight=\"balanced\",\n",
    "        probability=False,    # keep False for speed\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Run & collect metrics\n",
    "res_lin = evaluate_model(\"LinearSVC (scaled)\", linear_svm, X_train, y_train, X_test, y_test)\n",
    "res_rbf = evaluate_model(f\"SVC RBF + PCA({n_pca})\", svm_pca_rbf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Compact summary\n",
    "import pandas as pd\n",
    "summary = pd.DataFrame([res_lin, res_rbf]).sort_values(\"macro_f1\", ascending=False)\n",
    "print(\"\\nSummary (sorted by Macro-F1):\")\n",
    "print(summary.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
